____________________________________________________________

Logistic Regression
Accuracy: 0.8553
____________________________________________________________
              precision  recall  f1-score  support
0                0.8667  0.7879    0.8254     33.0
1                0.8478  0.9070    0.8764     43.0
macro avg        0.8572  0.8474    0.8509     76.0
weighted avg     0.8560  0.8553    0.8543     76.0
____________________________________________________________
____________________________________________________________

Decision Tree
Accuracy: 0.7763
____________________________________________________________
              precision  recall  f1-score  support
0                0.7353  0.7576    0.7463     33.0
1                0.8095  0.7907    0.8000     43.0
macro avg        0.7724  0.7741    0.7731     76.0
weighted avg     0.7773  0.7763    0.7767     76.0
____________________________________________________________
____________________________________________________________

Naive Bayes
Accuracy: 0.8421
____________________________________________________________
              precision  recall  f1-score  support
0                0.8621  0.7576    0.8065     33.0
1                0.8298  0.9070    0.8667     43.0
macro avg        0.8459  0.8323    0.8366     76.0
weighted avg     0.8438  0.8421    0.8405     76.0
____________________________________________________________
____________________________________________________________

KNN
Accuracy: 0.8289
____________________________________________________________
              precision  recall  f1-score  support
0                0.8333  0.7576    0.7937     33.0
1                0.8261  0.8837    0.8539     43.0
macro avg        0.8297  0.8206    0.8238     76.0
weighted avg     0.8292  0.8289    0.8278     76.0
____________________________________________________________
____________________________________________________________

Random Forest
Accuracy: 0.8158
____________________________________________________________
              precision  recall  f1-score  support
0                0.8065  0.7576    0.7812     33.0
1                0.8222  0.8605    0.8409     43.0
macro avg        0.8143  0.8090    0.8111     76.0
weighted avg     0.8154  0.8158    0.8150     76.0
____________________________________________________________
____________________________________________________________

GBC
Accuracy: 0.8421
____________________________________________________________
              precision  recall  f1-score  support
0                0.8387  0.7879    0.8125     33.0
1                0.8444  0.8837    0.8636     43.0
macro avg        0.8416  0.8358    0.8381     76.0
weighted avg     0.8420  0.8421    0.8414     76.0
____________________________________________________________
____________________________________________________________

XGB
Accuracy: 0.8026
____________________________________________________________
              precision  recall  f1-score  support
0                0.7647  0.7879    0.7761     33.0
1                0.8333  0.8140    0.8235     43.0
macro avg        0.7990  0.8009    0.7998     76.0
weighted avg     0.8035  0.8026    0.8029     76.0
____________________________________________________________
____________________________________________________________

LGBM
Accuracy: 0.8289
____________________________________________________________
              precision  recall  f1-score  support
0                0.8125  0.7879    0.8000     33.0
1                0.8409  0.8605    0.8506     43.0
macro avg        0.8267  0.8242    0.8253     76.0
weighted avg     0.8286  0.8289    0.8286     76.0
____________________________________________________________
____________________________________________________________

Cat
Accuracy: 0.8289
____________________________________________________________
              precision  recall  f1-score  support
0                0.8125  0.7879    0.8000     33.0
1                0.8409  0.8605    0.8506     43.0
macro avg        0.8267  0.8242    0.8253     76.0
weighted avg     0.8286  0.8289    0.8286     76.0
____________________________________________________________
